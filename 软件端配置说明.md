# 智能盆栽IoT项目 - 软件端配置说明

## 项目概述

本项目是一个基于ESP32的智能盆栽交互系统，通过Wi-Fi连接实现：
- **语音识别对话**：ESP32麦克风采集音频，上传到服务器进行语音识别和对话
- **动作识别**：ESP32摄像头捕获图像，服务器识别用户动作（挥手、点头、摇头等）
- **Web监控**：实时查看对话日志、湿度数据和系统状态

---

## 🏗️ 系统架构

```
┌─────────────────────────┐
│   ESP32硬件设备         │
│  - I2S麦克风(SPH0645)   │
│  - I2S扬声器(MAX98357A) │
│  - ESP32-CAM摄像头      │
│  - OLED显示屏(SSD1306)  │
└──────────┬──────────────┘
           │ Wi-Fi (Columbia University)
           │ HTTP POST (音频/图像数据)
           ▼
┌─────────────────────────┐
│  Flask Web服务器        │
│  - 语音识别(Google API) │
│  - 动作识别(MediaPipe)  │
│  - 对话管理             │
│  - 数据存储             │
└──────────┬──────────────┘
           │ HTTP GET
           ▼
┌─────────────────────────┐
│  Web前端界面            │
│  - 实时日志显示         │
│  - 湿度监控             │
│  - 对话控制             │
└─────────────────────────┘
```

---

## 📋 硬件引脚配置参考

### I2S麦克风 (SPH0645)
| 功能 | ESP32引脚 |
|------|----------|
| BCLK | GPIO 14  |
| LRCL/WS | GPIO 15 |
| DOUT | GPIO 32 |

### I2S扬声器/功放 (MAX98357A)
| 功能 | ESP32引脚 |
|------|----------|
| BCLK | GPIO 26  |
| LRCL/WS | GPIO 25 |
| DIN | GPIO 22 |

### OLED显示屏 (SSD1306)
| 功能 | ESP32引脚 |
|------|----------|
| SCL | GPIO 22 |
| SDA | GPIO 21 |

### ESP32-CAM摄像头
使用ESP32-CAM模块的固定引脚，无需额外配置。

### 音频参数
- 采样率：16000 Hz
- 位深：16-bit
- 通道：单声道
- 录音时长：3秒/次

---

## 🚀 软件端部署步骤

### 步骤1: 安装Python依赖

在项目的 `Web/` 目录下安装所需依赖：

```bash
cd Web/
pip install -r requirements.txt
```

依赖包括：
- `Flask` - Web服务器框架
- `SpeechRecognition` - 语音识别库
- `opencv-python` - 图像处理
- `mediapipe` - 动作识别
- `numpy` - 数值计算
- `pyngrok` - 公网访问（可选）

### 步骤2: 配置服务器IP地址

**重要**：需要将你的电脑IP地址配置到硬件端。

1. 查看你的电脑在Columbia University Wi-Fi下的IP地址：
   ```bash
   # macOS/Linux
   ifconfig | grep "inet "

   # Windows
   ipconfig
   ```

2. 编辑 `Hardware/config.py` 文件，修改服务器地址：
   ```python
   SERVER_BASE_URL = "http://你的电脑IP:8080"  # 例如 http://10.207.99.24:8080
   ```

### 步骤3: 启动Web服务器

在 `Web/` 目录下运行：

```bash
python app.py
```

你会看到：
```
============================================================
🌱 智能盆栽Web监控系统
============================================================
本地访问地址: http://localhost:8080
局域网访问地址: http://[你的IP]:8080

💡 提示:
  - 如需外网访问，请使用 ngrok 或 localtunnel
  - 按 Ctrl+C 停止服务器
============================================================
```

### 步骤4: 访问Web界面

在浏览器中打开：`http://localhost:8080`

你会看到：
- **湿度监控图表**（左侧）
- **对话控制按钮**（右侧）
- **实时活动日志**（底部）

---

## 🔧 功能说明

### 1. 语音识别对话流程

**触发方式**：
1. 在Web界面点击"开启对话"按钮
2. ESP32会定期检测对话状态
3. 当对话激活时，ESP32开始录音（3秒）
4. 音频上传到服务器识别

**对话指令**：
- 说 "hello world" → 激活对话模式
- 说 "bye bye" 或 "goodbye" → 结束对话

**支持的对话示例**：
- "How are you?" → "I'm doing great! Thanks for asking."
- "What is your name?" → "I'm your smart plant assistant. You can call me Planty!"
- "Tell me a joke" → "Why did the plant go to therapy? Because it had too many deep roots!"
- "Water" → "Remember to water your plants regularly!"

**技术细节**：
- ESP32使用I2S麦克风采集16kHz, 16-bit PCM音频
- 音频通过HTTP POST发送到 `/api/speech` 端点
- 服务器使用Google语音识别API（免费，需要联网）
- 返回识别文本和机器人回复

### 2. 动作识别功能

**识别的动作**：
| 动作 | 输出 | 触发条件 |
|------|------|---------|
| 挥手打招呼 | "Hi" | 手举高并左右摆动 |
| 双手举高 | "Wow" | 双手都高于头部 |
| 鼓掌 | "Good" | 双手快速靠近分开 |
| 点头 | "Yes" | 头部上下移动 |
| 摇头 | "No" | 头部左右摆动 |

**工作流程**：
1. ESP32-CAM每2秒捕获一张JPEG图像
2. 图像通过HTTP POST发送到 `/api/gesture` 端点
3. 服务器使用MediaPipe Pose模型检测人体姿态
4. 分析关键点位置变化识别动作
5. 返回识别结果到ESP32

**技术细节**：
- 图像分辨率：QVGA (320x240)
- JPEG质量：10（较低质量，减少传输数据量）
- 使用轻量级Pose模型（`model_complexity=0`）
- 2秒冷却时间避免重复识别

### 3. Web监控界面

**功能模块**：

1. **湿度监控**
   - 显示过去24小时湿度趋势图
   - 实时统计当前/平均湿度
   - 每5秒自动刷新

2. **对话控制**
   - 查看对话状态（活跃/已关闭）
   - 开启/关闭对话按钮
   - 手动刷新数据

3. **实时活动日志**
   - 显示最新50条活动记录
   - 颜色分类：
     - 系统消息（蓝紫色）
     - 用户语音（蓝色）
     - 机器人回复（绿色）
     - 动作识别（粉色）
   - 按时间倒序排列

---

## 🌐 网络配置

### Wi-Fi设置

确保ESP32和你的电脑都连接到 **Columbia University** Wi-Fi。

在 `Hardware/config.py` 中配置：
```python
WIFI_SSID = "Columbia University"
WIFI_PASSWORD = ""  # 如果有密码则填写
```

### API端点

服务器提供以下API端点：

| 方法 | 端点 | 功能 |
|------|------|------|
| GET | `/` | Web界面 |
| GET | `/api/conversation/status` | 查询对话状态 |
| POST | `/api/conversation/start` | 开启对话 |
| POST | `/api/conversation/stop` | 关闭对话 |
| POST | `/api/speech` | 接收音频，返回识别和回复 |
| POST | `/api/gesture` | 接收图像，返回识别动作 |
| GET | `/api/conversation/log` | 获取对话记录 |
| GET | `/api/humidity` | 获取湿度数据 |
| POST | `/api/humidity/add` | 添加湿度数据 |

---

## 📊 数据流示意

### 语音识别数据流
```
ESP32麦克风 → PCM音频 (16kHz, 16bit, 3秒 = 96KB)
     ↓
HTTP POST /api/speech
     ↓
服务器语音识别 (Google API)
     ↓
对话逻辑处理
     ↓
返回JSON: {"user": "识别文本", "bot": "回复文本", "action": ""}
     ↓
ESP32显示到OLED屏幕
```

### 动作识别数据流
```
ESP32-CAM → JPEG图像 (320x240, 质量10, ~10-20KB)
     ↓
HTTP POST /api/gesture
     ↓
服务器动作识别 (MediaPipe Pose)
     ↓
姿态检测 + 动作判断
     ↓
返回JSON: {"gesture": "Hi|Wow|Good|Yes|No|null"}
     ↓
ESP32显示到OLED屏幕
```

---

## 🔍 调试和测试

### 查看服务器日志

运行Web服务器时，控制台会实时显示：
```
接收到音频数据: 96000 字节
✅ 识别到: hello world
🤖 回复: Hello! I'm your smart plant. How can I help you today?

接收到图像数据: 15234 字节
✅ 识别到动作: Hi
```

### 常见问题排查

1. **语音识别失败**
   - 检查网络连接（需要访问Google API）
   - 确保音频数据大小正确（约96KB）
   - 说话清晰，避免环境噪音

2. **动作识别不准确**
   - 确保光线充足
   - 站在摄像头前，全身或上半身可见
   - 动作幅度要明显
   - 检查2秒冷却时间

3. **ESP32连接失败**
   - 确认服务器IP地址正确
   - 确认两者在同一Wi-Fi网络
   - 检查防火墙设置（开放8080端口）

### 测试步骤

1. **测试Web服务器**
   ```bash
   cd Web/
   python app.py
   # 访问 http://localhost:8080
   ```

2. **测试API端点**（使用curl）
   ```bash
   # 测试对话状态
   curl http://localhost:8080/api/conversation/status

   # 开启对话
   curl -X POST http://localhost:8080/api/conversation/start
   ```

3. **模拟ESP32上传音频**（需要准备PCM音频文件）
   ```bash
   curl -X POST http://localhost:8080/api/speech \
        -H "Content-Type: application/octet-stream" \
        --data-binary @test_audio.pcm
   ```

---

## 📁 项目文件结构

```
Iot_Project/
├── Hardware/               # ESP32硬件端代码
│   ├── main.py            # 主程序
│   ├── config.py          # 配置文件（需修改服务器IP）
│   ├── wifi_manager.py    # Wi-Fi连接
│   ├── mic_module.py      # 麦克风模块
│   ├── speaker_module.py  # 扬声器模块
│   ├── oled_module.py     # OLED显示
│   └── camera_module.py   # 摄像头模块
│
├── Web/                   # Web服务器端
│   ├── app.py             # 主应用（已修改，支持音频/图像处理）
│   ├── requirements.txt   # Python依赖（已更新）
│   ├── templates/
│   │   └── index.html     # Web界面
│   └── data/
│       ├── humidity_data.json      # 湿度数据
│       └── conversation_log.json   # 对话日志
│
├── Voice/                 # 本地语音识别（仅供参考）
│   └── voice_recognition.py
│
├── Gesture/               # 本地动作识别（仅供参考）
│   └── gesture_recognition.py
│
└── 软件端配置说明.md      # 本文档
```

---

## ⚙️ 主要修改内容

### 修改的文件：

1. **Web/app.py**
   - ✅ 添加 `ServerVoiceRecognizer` 类 - 处理ESP32上传的PCM音频
   - ✅ 添加 `ServerGestureRecognizer` 类 - 处理ESP32上传的JPEG图像
   - ✅ 修改 `/api/speech` 端点 - 从接收JSON改为接收PCM二进制数据
   - ✅ 修改 `/api/gesture` 端点 - 从接收JSON改为接收JPEG二进制数据
   - ✅ 集成语音识别和对话逻辑
   - ✅ 集成动作识别逻辑

2. **Web/requirements.txt**
   - ✅ 添加 `SpeechRecognition==3.10.0`
   - ✅ 添加 `opencv-python==4.8.0.74`
   - ✅ 添加 `mediapipe==0.10.3`
   - ✅ 添加 `numpy==1.24.3`

### 未修改的部分：

- `Hardware/` 目录下的所有文件（硬件组员负责）
- `Voice/voice_recognition.py`（保留作为参考）
- `Gesture/gesture_recognition.py`（保留作为参考）
- Web前端界面（已满足需求）

---

## 🎯 下一步工作

1. **硬件组员任务**：
   - 确保ESP32硬件按照引脚配置正确连接
   - 上传 `Hardware/` 目录下的代码到ESP32
   - 修改 `Hardware/config.py` 中的服务器IP地址
   - 测试Wi-Fi连接

2. **软件组员任务**：
   - 在你的电脑上运行Web服务器
   - 确保电脑和ESP32在同一Wi-Fi（Columbia University）
   - 测试API端点是否正常工作
   - 监控服务器日志

3. **集成测试**：
   - ESP32连接到Web服务器
   - 测试语音识别对话功能
   - 测试动作识别功能
   - 查看Web界面实时日志

---

## 📞 技术支持

### 语音识别相关
- 使用Google Speech Recognition API（免费，需联网）
- 支持英文识别（`language='en-US'`）
- 如需离线识别，可考虑使用Vosk或其他离线模型

### 动作识别相关
- 使用MediaPipe Pose轻量级模型
- 最小检测置信度：0.5
- 冷却时间：2秒

### 网络相关
- 确保Columbia University Wi-Fi允许设备间通信
- 如遇防火墙问题，可尝试关闭防火墙或添加端口例外
- 如需公网访问，可使用 `app_public.py` 启动ngrok隧道

---

## 📝 版本历史

**v1.0** (2025-12-05)
- ✅ 完成Web服务器音频处理功能
- ✅ 完成Web服务器图像处理功能
- ✅ 集成语音识别和对话逻辑
- ✅ 集成动作识别逻辑
- ✅ 更新依赖文件
- ✅ 编写配置说明文档

---

## 📄 许可证

本项目为教育用途，遵循Columbia University相关规定。
